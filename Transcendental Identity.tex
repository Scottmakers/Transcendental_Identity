\documentclass{article}
\title{Transcendental Identity - An Experiment in Cyberspace}
\date{04/15/2016}
\author{Scott M. Akers et. al.}
\begin{document}
	\pagenumbering{gobble}
	\maketitle
	\newpage
	\pagenumbering{roman}

	\tableofcontents
	\newpage
\section{Abstract}
	What is the meaning of identity in the information age?  We use a complex set of documents, contracts, accounts, keys etc. to define our existence in society.  Subjectivley, we use belief systems, methods of communicating, and a plethora of qualitative characteristics to define our identity in relation to the world.  This uniquely human characteristic ||the discovery and expression of identity|| ranges from the scientific theories of particle physics, to the theological exploration of God.  The dawn of the information age and commercialization of the internet gives us an accessible context to explore and share knowledge in a profound way, however, the increasing complexity and density of information available is beyond our evolutionary capability, leaving us ill-equipped to process, categorize, and parse information into meaningful Truth.  Evidenced by the "Post-truth" era of information, we are in the midst of a pandemic identity crisis that manifests disorder, dissention, and chaos.  Conflicting beliefs, the censorship of ideas, and the lack of logical discipline in web-content places the individual at a distinct disadvantage - where ideas and feedback loops cause dangerous psychological damage to our wellbeing.  The disharmonies in information exchange, translation and interpretation pose an existential threat to the continued development of civilization.   \\\\ 
Abstracting from the human: our quest to discover scientific truth is ever-increasing by method and measurement giving us a rich understanding of of the physical world at a subatomic and astrological scale.  Sadly, the identities of scientific truth stand apart from one-another, rendering each discipline a tree among the rich forest of discovery.  Our hope is to define the fundamental components of information and define a healthy digital identity during our global transition into the cybernetic age. 
 
\section{Overview}
Inspiration for this work came from analyzing and sampling a vast range of philosophical, technological and scientific disciplines.  Our analysis yielded patterns and informational commonalities that cut across seemingly unrelated subject matters. This experiment is an attempt to simplify the components of, relationships between, and means of expression of informational Identity(i) that is mathematically consistent and computationally sound.  Extending the exploration, we seek to provide datalogical paralells in a concise framework and a logical proofing system that can be applied across the information space.  The end goal of this experiment is to define the datum of Identity, the definition of datalogical value, and the fundamental transactional vectors of datalogical expression.  More specifically, this paper (1) measures and defines the key components of identity and information science (ontology), (2) describes the axioms of an identity management with regard to mathematics and computer science, and (3) characterizes the wide applications of identity science to improve our understanding of transcendental truths of existence.  Our goal is to create an infological toolkit that obliterates information disharmony and grounds the nature of information in a mathematically consistent, computationally sound way.  Further exploration is required to rigorously exhaust the full scope of Identity Science, its implications, and applications to cybernetic systems.

\subsection{Design Assumptions}
To best explicate the idea of transcendental identity, we pull on resources from all fields of mathematics, science, theology, and philosophy to encapsulate the full nature of existence.  By taking a firm viewpoint (assumption) that we posess ‘identity’ in concept and in fact, we  establish a critical junction-point for existence.  Identity Science is the effort to condense all conceivable forms of information into an objective, measurable, and actionable expression media that carries fidelity (truth) from origin to expression.  Extending this concept, we will apply Identity Science to human meaningful identity, Human meaningful assertions about system security, and the identity of fundamental particles in science.  To bind this framework, we rely heavily on the use of (1)numerals and glyphs to create unique identity signatures, (2)existing mathematical proofs to define the relationships between numerical identities, and (3)Objective definitions of non-reducible information types.  We require that any information exchange maintains logical fidelity (traceability), security (recognition of genuine expression), and historical auditability (permanance of exisitence).\\\\
The thought experiment is expressed from the standpoint of a n-dimensional being asking an n-1 dimensional being a question about that their identity in the n-1 dimensional plane. 

\subsection{Expected Results}
We expect the n-1 dimensional being to be able to point at artifacts in the n-1 dimensional environment that proves a reasonable context to their existence.  These artifacts, when taken as a whole data-point, from the n-dimensional being perspective, would provide context to prove that the n-1 being does indeed exist in the n-dimensional plane.

\subsection{Counter Arguments}
Arguments can be made that the n-dimensional being takes a certain form and that one particular form would be molded to provoke thought in the most effective way possible given the existing social and technological context.  We expect a higher-dimensional being to utilize lower-order dimensional characteristics to deliver information to a lower-order dimensional being.  The philosophical and theological implications of this experiement require futher exploration.  This work is open to refutation and improvement of this framework requires exhaustive application of it's components to all areas of universal existence.  We refute any argument that inappropriately places subjective divinity onto an identity.  By method, we explicitly refute instances of gods, prophets, or agents who reduce the survivability of human civilization, undermine technological progress towards a Type 1 civilization or violate Human Rights as defined in the UN UDHR.

\subsection{Limitations}
In the context of science, we must consider advancements that have been made toward the microcontent of particle physics, and the macrocontent of universal astrophysics.  It is argued that these two fields of study are maximally inclusive based on the measurement tools that are being used to discover our place in spacetime and in reality.  It is strongly supported that there are linkages between the two.  Recent advancements in gravitational string theory provide a lens that allows us to measure the most fundamental linkages between matter at an astrophysical level, and provide insight into gravity’s instantiation in particle physics.\\
In the context of Theology, we must consider the impact that n+1 dimensional beings would have in a social, political, and physical context.  There is explicit recognition that n+1 dimensional beings are capable of operating within physical vector spaces.\\ 
In the context of Philosophy, we must consider the natural limitations of the human mind.  While the human brain is considered to be the most powerful information processing machine known, there are limitations to the data that can be collected.  We are driven as organisms to use artificial constructs or philosophical images to “make sense” of the information that is presented to us. Some constructs will be measurably advantageous to our survival while other images, indicated by cybernetic patterns, may uncover unpredictable circumstances that render disadvantage to the system.  Historically, these patterns have been expressed in religious texts, historical documents, government charters, and works of art and literature.  In contemporary society (2016) memetics is an new area of discovery that circumscribes identity science.\\
At the outset of this exploration of identity modeling, it should be noted that the concepts contained here are meant as a functional process to smooth the disharmonies in the information space and simplify or unify data models that express data. 

\section{Definition of Terms}

\textbf{Identity:} A singular immeasurable object in a dimensional plane that must use other objects to provide context to its existence. This is the negative (null) space that has no characteristics, all instances of identity are exhausted through contextualization – not existence itself. \\
\textbf{Event:} an instance of space-time that brings n-disparate non-reducible datum into union, creating an interference. \\
\textbf{Time:} a warping or translation of space between two datum. \\
\textbf{Action:} a state that maximizes or minimizes the resolution of unknown processes.\\ 
\textbf{Dimension:} a bounded vector space wherein datum is expressed. \\
\textbf{Agent:} a structure whose integrity stands to gain or lose from the resolution of known processes.\\   
\textbf{Process:} the total unitary set of agent-action relations within a given event space. \\
\textbf{Datum:} a singular unit of information. \\\\
\textbf{Albert:} an n+1 dimensional being. \\
\textbf{Margaret:} an n-dimensional being. \\

\section{Methodologies}
With great help from God, the planet earth, humans, and the technologies that have gotten us so far. Thank you to all the families out there. Real and Digital.  \\
I am concerned with the accurate measurement of information contained in this paper. I do not claim intellectual superiority over existing measurement methods and their results. Nor can I refute the validity of measurements outside of my understanding. \\

\section{Thought Experiments in Cyberspace}
Hypotheses: \\\\
1) All information in the universe is composed of at least 1 Datum. \\
2) Identity is the sum of events at a given space/time that creates an identifiable interference pattern.\\
3) An interference pattern occurs at the intersection of two values\\ 

\subsection{Experiment 1 - Defining Identity as Degrees of Value}
\textbf{||Begin Event||} \\
\textbf{Albert:} Hello Margaret. \\
\textbf{Margaret:} Hello Albert. \\
\textbf{A:} Margaret, what is your identity? \\
\textbf{ M:} What is my Identity? My identity is my physical body, my birth certificate, my social security card, my bank account, my email, my social media profile, my phone apps, and the unique data contained there.  My house is represented by my deed. My car is represented by my title document.  My diet is this. my gender is this.\\
\textbf{||End Event||} \\
\textbf{||Explanation of Event||} \\(Object) An object is comprised of at least 1 Datum of information.  Margaret uses her [name] object to most closely describe her [identity].  Supporting the identity claim, she uses contextual data to more clearly define other datum that describes her identity.  Those datum can be qualified as person or property. Real, personal, intellectual, or fictitious.  In computer science, an object can be expressed as any unique, observable pattern of data.\\\\
The event encapsulates all that was said between Albert and Margaret.  Albert and Margaret are interference patterns that instantiate at the event T= 0.  All prior events are insignificant.  Because Albert is asking a question “what is your identity?”, Margaret instantiates a unique pattern of data that can be linked to the identity of Margaret. \\\\
\textbf{||Begin Event||} \\
\textbf{A:} Those are all forms of datum.  You are made of those datum. I would like to ask, Where is your identity? \\
\textbf{M:} Where is my Identity? I suppose it is housed somewhere in those documents. \\
\textbf{A:} Do you have control of your identity? \\
\textbf{M:} Yes. But I have an agent system that manages my identity \\
\textbf{A:} Do you feel that the agent is doing its best to protect your identity? \\
\textbf{M:} I believe they do provide protection. \\
\textbf{A:} Do they provide absolute, uncensored access to your identity? Is that system always available? Is that system accessible, given your understanding of technology? \\
\textbf{M:} I believe it does. \\
\textbf{A:} Does that system make you feel safe about where your identity is? \\
\textbf{M:} Yes. \\
\textbf{A:} You have a very secure sense of identity.  This is enough evidence to prove you exist. \\
\textbf{||End Event||} \\
\textbf{||Explanation||} \\(Assertion) An assertion is an object that defines a series of events to link an identity to context data.  In computer science, an assertion would take the form of a chain of receipts.  Keep in mind, the content or “metadata” associated with the assertion does not need to be included as information.  Meta-data would be considered n-1 information in relation to the ‘Margaret’ identity.\\\\
\textbf{||Begin Event||} \\
\textbf{M:} … thank you? \\ 
\textbf{A:} Does your identity provide the things you need to live your life in the way you would like? \\
\textbf{M:} I believe my identity provides some things.  Other things, I must get for myself. \\
\textbf{A:} What are those things? \\
\textbf{M:} Water, Food, Shelter, Access to my identity.  My creative outlets, my sense of adventure, and my purpose in life are things I must find for myself. \\ 
\textbf{A:} Do the agents that manage your identity make it easier to pursue the thing that makes you happiest? \\
\textbf{M:} I do. \\
\textbf{A:} You have a healthy identity \\
\textbf{M:} That is good to know. \\
\textbf{||End Event||} \\
\textbf{||Explanation||} \\ (Value) – Value is the relative recognition of an identity.  Values are expressed as an object or assertion. \\
1 Datum of value exists in 1 dimension. A concept has 2 degrees of value but maintains an informational mass of 1 datum in the first dimension. The intersection of a value and a concept represents a matter; matter is a 3rd dimensional datum and contains the characteristics of physical matter such as a proton or neutron.

\subsection{Experiment 2 - Defining an Identity with Purpose}
For this experiment, assume Albert is an n+1 capable machine with 5 basic buttons and 5 sub-selections.  he is at a fixed location. \\\\
\textbf{||Begin Event||} \\
\textbf{A:} Hello Margaret\\ 
\textbf{M:} Hello Albert \\
\textbf{A:} Where would you like to go? \\ 
\textbf{M:} I don’t know.  Can you show me where I am? \\ 
\textbf{A:} You are here [Map] – on 1234 main street.  From here, you can do 5 things. [Facilities][Food][Shelter][Explore][Meet] \\
\textbf{M:} Thank you, Albert \\
\textbf{||End Event||} \\
\textbf{||Event Explanation||} Unconstrained purpose is simply defined as an identity interacting with a validator node.  Validation nodes (V) provide n+1 context to the n-dimension identity.  Information can be preselected based on the identity’s preferences, data peers, or other context specific information.  Important transactions like notarizing a document require Observers(O) to corroborate validation and propagate valid transactions through a network.  Proper validation requires O>V. \\\\

\subsection{Experiment 3 - Margaret The Photon}
This experiment seeks to understand what a photon would say to an observer that could travel at the speed of light, and asking what the identity is, and the contextual information that asserts datalogical mass. \\
\textbf{||Begin Event||} \\
\textbf{A:} Hello Margaret \\
\textbf{M:} Hello Albert \\
\textbf{A:} What is your identity? \\
\textbf{M:} I am an interference pattern of [energy]. (concept) \\
\textbf{A:} Where is your identity? \\
\textbf{M:} The speed of light. Now. \\
\textbf{||End Event||} \\
\textbf{||Event Explanation||}\\\\
This experiment seeks to encapsulate the identity data in a photon of light.  Traditional measurements have proven that a photon acts as a wave and a particle.  Our hope is that identity science can bridge data models in particle physics to scientific disciplines.

\section{Measurements of Identity}
\textbf{Identity $\dot \iota$, $\hat \iota$, $\tilde \iota$} - The object that instantiates an event; Identity can come from any of n dimensions, dimensionality is notated through alephs on top of the greek character iota. (A dot that traverses a circle onto itself)  \\
\textbf{Datum $\dot \Delta$} - datalogical mass; all information contains 1 datum. (A dot) \\
\textbf{Value $\dot \Upsilon$, $\hat \Upsilon$, $\tilde \Upsilon$} - Any identifiable interference pattern contains value; Value occurs as an object, assertion, or a combination thereof. (a dot at the intersection of 2 vectors)  \\
\textbf{Assertion $\dot \alpha$, $\hat \alpha$, $\tilde \alpha$} - a type of value, denoted with alephs over the greek letter alpha. (A line/ray that radiates from a dot)\\
\textbf{Object -  $\dot \Omega$, $\hat \Omega$, $\tilde \Omega$} - a type of value, dimensionality is denoted by alephs over the greek letter omega. (a dot connected to a dot by a line) \\
\textbf{Event  $\dot \varepsilon$, $\hat \varepsilon$, $\tilde \varepsilon$} - the space in which a value occurs; Events can occur at any dimension.  Dimensionality is notated through alephs over the greek letter epsilon. (a bounded mathematical field with maximal entropy for a given identity) \\
These measurements seek to deconstruct the information presented as a complex sequence of disparate data.  In different degrees of dimensionality, there are multiple datum that contribute to identifying a particular concept.

\section{Conclusion from Measurements}
These measurements provide basic tools to quantify data in simplified way.  Key to this simplification is recognition of the notion that an identity itself is null, and the identity must point to contextual information to prove its existence. 
We can reductively show through this lens that all information is the interference of datum at a particular point in space, and that time is simply the warping of space between those interference patterns.  Time duration is a quantum event.

Maximalizing this notion and by refactoring all available datasets, we posit that identity is the sum of all events at Time = 0.\\

	\begin{equation}
		\dot \iota = \sum_{\tau=0}^{i=PK_0} \epsilon^i_\upsilon
	\end{equation}
 		


\section{Identity Modelling within a defined mathematical field}
	\subsection{Method Requirements}
			\subparagraph{Steps to create a mathematical identity}
			\begin{enumerate}
				\item Create Root Identification Key ($PK_0$)  THIS IS THE IDENTITY.  The value must be sufficient to answer: what is the identity?
				\item Document planar field/event space parameters.  THIS IS THE CONTEXT (Event Space).  The value must be sufficient to answer: where is the identity? what is it sub-ordinate to? what is it super-ordinate to?
				\item Determine value coordinates within event space by function. The coordinates must be sufficient to answer: how did the identity express itself?  As an object? As an assertion? What are the values that intersect?
				\item Broadcast from Validator($V_n$) to n+1 Observers.  Does the identity meet data validation requirements for propagation across a network?
				\item Submit Object/Assertion to concensus artifact;  f(x) = OP-RETURN;  The Distributed hash table of a blockchain system is a concensus artifact.  There must be more than 1 observation/confirmation that the object is included in the concensus artifact. Confirmation represents that sufficient energy was expended to express the object across all instances of the concensus artifact. (OP-Return + Confirmation)  
			\end{enumerate}			
			RETURN:  Identity Location ($PublicActionKey_1$),  Transaction ID ($TX_i$), Transaction Endpoint ($TX_e$).
			\subparagraph{Computational Transformations of a Mathematical identity}
				This array is a base case for the computation of i. \\

				\begin{array}{|l|c c c c c c c c|l|}
					\hline
					$\dot \iota^1$ & v_1 & v_2 & v_3 & v_4 & v_5 & v_6 & v_7 & v_8 & $\dot \iota_1$ \\		
					\hline
					0 & 0 & 00 & \omega & 
 & v_1 & v_1 & v_1 & v_1 & 0\\
					1 & 1 & 01 & \alpha &  & v_1 & v_1 & v_1 & v_1 & 1\\
					0 & 0 & 00 & \omega & v_1 & v_1 & v_1 & v_1 & v_1 & 0\\
					0 & 0 & 00 & \omega & v_1 & v_1 & v_1 & v_1 & v_1 & 0\\
					1 & 1 & 01 & \alpha & v_1 & v_1 & v_1 & v_1 & v_1 & 1\\
					0 & 0 & 00 & \omega & v_1 & v_1 & v_1 & v_1 & v_1 & 0\\
					0 & 0 & 00 & \omega & v_1 & v_1 & v_1 & v_1 & v_1 & 0\\
					1 & 1 & 00 & \alpha & v_1 & v_1 & v_1 & v_1 & v_1 & 1\\
					\hline

				\end{array}
		\subsection{Axioms for Consideration}These are the logcal boundaries to use when evaluating an identity.
			\subparagraph{Value as a Unique Identity}
				Anything that contains datalogical uniqueness is valueable, anything that is not seen or representative of value within a context is excluded from consideration
			\subparagraph{Explicit Differentiability between objects(identities)}
				To avoid computational collisions, unique identities are in-fact and in-function identical.  Any non-unique value must either be subsumed by the principal identity or must be instantiated in a different dimension (alternate cardinality) 
			\subparagraph{Object Traversal recognized as a transaction}
				Computed transactions of an identity are a mathematically reproducible vector in an event space.
			\subparagraph{Assertions are independent of Objects}
				An assertion or vector contains its own uniqueness and is not required to be associated with a particular object.
			\subparagraph{Bounded set for Identity Measurement(Field of Expression)}
				Measurement of an identity must occur within a bounded vector-space.
			\subparagraph{Identity Kernel}
				The artifact that creates a computational space.  The value of any transaction or object in the identity kernel must have less entropy than the identity itself.
			\subparagraph{Computational Expression of Cryptographic Identities}
				A simple example of an identity is a SHA 256 public key address which has been derived from a Private Key datastring.
			\subparagraph{Concensus Mechanisms as data validators}
				A blockchain systems provides $n^n$ network validators.
			\subparagraph{Rules of Recognition and Ordinality}
				Identity system management over a sufficiently large number of participants requires rules that indicate peer, non-peer, sub-ordinate, and super-ordinate identities. (IoT)
			
\section{Very Large Numbers and the Mathematics of Identity}
		\paragraph{Cantor's Proof} Infinite set of Infinities - Cantor's proof accounts for $\infty^\infty$ cardinalities through which we can express mathematical identities.  Human meaningful mathematical identities exist in a bounded set of extremely large numbers.  In Mathematics, Graham's Number or the largest known prime number can be considered the boundary of entropy for mathematical calculation. 
		\paragraph{Known Limits and boundaries to Very Large numbers} Computational limits and practical data management.  within the scope of computer science, we define a digital identity as string of characters with up-to $36^\infty$ digits, however, for the sake of practical computation and expression of an identity, we create an artificial number limit of $36^{64}$ ($4.01 X10^{99}$) to provide sufficient entropy in a finite state machine.   
		\paragraph{Category Equalizers} Category equalizer graphs are sufficient to describe identity morphisms within and between sets.
		\paragraph{Philosophical Dualism} Bridging the finite state machine to conscious reality.  We hypothesize that it is possible to mirror physical and metaphysical processes in a finite state machine.  Further exploration of this paradigm may lead to the objective proof of simulations of reality.
		\paragraph{Euclidean Geometry} The Axioms of Euclidean Geometry hold true in the realm of identity science.
		\paragraph{Minkowski Space} The Mathematics of Identity Science exist in Minkowski Space, bounded by $\Pi$, $\Pi$.
		\paragraph{Irrational/Transcendental Numbers}  Naturally occurring unique numbers provide a rich canvas to express identity uniqueness.  Reducing this notion to the practical, we explicitly acknowledge that Irrational/transcendental numbers are necessary to provide deterministic computational boundaries for the expression of unique identities in the information space.
			\subparagraph{Pi} $\Pi$ in identity science is a (heretofore incomplete) deterministic calculation of ever-increasing mathematical entropy.  The location ($\Pi$, $\Pi$) in our Minkowski Universe Event Space is the canonical topology manifold in mathematics and the deterministic calculation boundary for computer processing.
			\subparagraph{imaginary i} is no longer imaginary and can be mathematically reduced to a fixed coordinate configuration in the Minkowski Universe Event Space.
			\subparagraph{Euler's Identity} we acknowledge that identity science necessitates Euler's Equation and Euler's number e.  
			\subparagraph{Non-Computable Numbers}  Further exploration of halting functions is necessary within identity mathematics.  It is acknowledged that these computational functions can be deterministically described with sufficient entropy. 
			\subparagraph{Roots of Unity or De Mauvre Numbers}  are a necessary component of the abelian groups used in identity science.  We expect that there are specific Roots of Unity that can describe exotic transformations of identities in the identity event space.
		\paragraph{Complex Numbers} referent of imaginary numbers
		\paragraph{Pi Pi Topology Manifold} utilizing finite state machines to create a mathematically consistent topology manifold.
		\paragraph{Mathematically Defined Information Types} coordinate functions, fixed keys, transaction hashes, wave forms.
		\paragraph{Abductive reasoning in light of Deductive Certainty}
				"Duck test" within identical fields yields measurement of objective/assertive similarities.
				(If we define a leg, and we define the action spaces a leg can fill, we can define a leg across multiple disparate action spaces)  (parallelism)
		\paragraph{Identity Science with Respect to Godel's Incompleteness theorem}
				The Identification of identities seeks to provide an expansive means of describing characteristics of the physical and non-physical universe.  To be the most effective reflection (identity) of information, it must abide by Godel's incompleteness theorem.  Functionally speaking, Identity science is an open-ended framework.
		\paragraph{Poincare Conjecture}
			The Identity Proof seeks to improve on Grigori Perelman's solution of the Poincare Conjecture through the ($\Pi$, $\Pi$) manifold (in Abelian space) by disambiguating dimensionality of diffeomorphic shapes.  In respect to diffeomorphisms, the Identity proof revokes time as the joint singularity across multi-dimensional shapes.  Perelman's proof allows for the creation of a periodic table of mathematical information types that can be reduced to repeatable computational processes in a finite state machine.
		

\subsection{Applications of Identity Science to Data Structures and computer science.}
		By creating a method of identity discovery and traversal, our goal is to reduce the computational steps required to express content and improve the fidelity of information in a given system.
			\subparagraph{Periodic Table of Information} PTI is a bridge that links explicit mathematical calculations to physical/functional computer processes at datalogical scale.  Locations on the PTI represent expressive functions acting on an identity within a defined context.  https://www.desmos.com/calculator/pje74vwlqd \\  PTI is a framework to explicate and understand fundamental mathematical processes in a computationally consistent way.  By using the data definitions provided in this paper, we can, in a mathematically consistent way, create a fault-tolerant, globally accessible, always available universal identity reference architecture.  	[Img]
	25 data types, 4 Context Control Link Types, 5 Link Relations, 7 fault-tolerant strategies for data discovery, 5 Mining Relationships, and 4 Identity/Asset types.
			\subparagraph{Applied Mathematics}  Garbage in, Garbage out.  No Such Garbage.
			\subparagraph{Unitary, Uniform, Reference Architecture} A theoretical data model for everything.
			\subparagraph{H-factor Media Types (Hypermedia)} Datastreams across hypermedia
			\subparagraph{T-Factor Media Types (Transmedia)} fixed datapoints across the cybernetic space.
			\subparagraph{IoT Address Schema} Treegraph of IoT peers, observers etc.
			\subparagraph{People, Content, Machines, Corporations} value exchange across identity types.
			\subparagraph{Software-defined Networks} trustless transaction execution within a scope.
			\subparagraph{Blockchain Mechanisms} Indifference of actors to payload agents
			\subparagraph{Informational Sublimation} refactoring of non-unique information or Mutual Annihilation of explicitly identical identity pairs
			\subparagraph{Functional glyphs for refactoring identity}Semantic analysis of Identity, Object, Assertion, Location, Validator, Observer, Process.   "Squibble" or Semantic Quantum Unitary Identity Block Binary Lexical Explication.  Hashtag[Identity]Hashtag; :[Object]: ; <Assertion> ; @location@ ; ![event]! ; %[Observer]% ; ^[Validator]^ ;  
			\subparagraph{Necessary Method of Defined Bounds}
				It is explicitly acknowledge that the bounded definition of any identity is directly correlated to the context it exists.  This definition uses "Pi", $\pi$, or $\Pi$ due to the computability and complexity of the number.  The $\Pi$, $\Pi$  universe is simply the best approximation of maximally inclusive entropy that can be calculated in an finite state machine.
			\subparagraph{Shannon's Mathematical Theory of Communication}
				\begin{equation}
					H \Rightarrow -K \sum_{i=1}^{n} \rho_i \log \rho_i 
				\end{equation}
				Shannon's information theory aligns with identity mathematics - The Identity Proof gives further confirmation to his calculations.  The Identity proof provides resolution to Shannon's Time measurement.
			\subparagraph{Methodical data Reduction with Cryptographic Proofing} We expect that the explicit creation of unique identity signatures allows for the elimination of non-unique data in computer science and storage.
			\subparagraph{Exploration of Primes} ECDSA Encryption and the use of distributed architecture to explore very large primes is a underway.  The technology is computationally sound and respects the laws of thermodynamics.
			\subparagraph{The Use of Public/PrivateKey Encryption to Express Cryptographic Identity through ring signatures}  Identity science is an attempt at creating a mathematical framework to govern message-passing between distinct cryptographic identities. If the rules of message-passing are sufficient to govern transformations between identities, then they are necessary for ring signature expression.
			\subparagraph{Fourier transformations} we expect Fourier transformations to inform the behavior of calculations made on an identity with respect to a non-null value.
			\subparagraph{Einstein's theory of Relativity with respect to identity data structures}
				\begin{equation}
				e=mc^2 \Rightarrow \tau=\Delta \Upsilon^2 \Rightarrow t= d^v_v
				\end{equation}
				Futher exploration of this concept is needed, however, it is strongly suggested that a finite state machine is capable of instantiating a deterministic computational pattern that replicates the characteristics of Einstein's Theory of relativity.
			\subparagraph{Spooky action at a distance}
				The mathematics of identity science are expected to abide by and be informed by quantum entanglement.  Oddities of the physical and quantum world should be able to be described by identity science.
			\subparagraph{Feynman Diagrams}
				The mathematics of identity science allow for multi-dimensional explication of Feynman graphs.
			\subparagraph{Quantum Dense coding with atomic qubits}
				\begin{equation}
					\Gamma = < \Psi_i | \rho_o | \Psi_i >
				\end{equation}
				\begin{equation}
					I = < i^0 | i_1 | i_0 >
				\end{equation}
				Further exploration of this concept is needed, however, it is strongly suggested that the boundaries that govern identity transformations can be directly applied to the creation of qubits for quantum dense computations.
			\subparagraph{Halting Functions}
				with respect to halting functions, identity mathematics and computation relys on changes in cardinality of an identity to indicate the cessation of a computational process.
\section{Appendix}
\subsection{Primitive Data Types}
\subparagraph{Hypotheses}
		\begin{enumerate}
			\item All things in the universe contain at least 1 datum of information. 
			\item Any measurable Identity is the sum of all events at time = 0.
			\item An identity exists at the intersection of two values. 
		\end{enumerate}
	
\subsection{Definition of Identity}

	\paragraph{Datalogical Definition}
		The object that instantiates an event; Identity can come from any of n dimensions in the Cybernetic Realm. \\
		\textbf{Parameters:} Requires a Non-Zero Token Value \\
		\textbf{Extensability:}  Universal\\
		\textbf{Entropy:}  Universal \\
		\textbf{Bounds:}  ($\pi$, $\pi$)  Any sufficiently large unique number. \\
		\textbf{Coordinate:} (0,0)  \\
		\textbf{CS Morphology:}  A Private Key that can be mathematically reproduced through computation, expressed in context as a Public key that signs transactions.  Binary:  01001001    Qubit Code: I \\
		\textbf{Expression:} Any string of symbols can be the expression of an identity.  The symbols can be used to describe any content type.  Principally, an identity is expressed as a serialized data string for transport over a network layer.  A sufficiently complex identity should be able to express a point, line, or waveform in a given context.\\
		\textbf{Computation:} The Identity value of any given context is a delimiter that indicates the creation of a defined identity.\\
			\begin{equation}
				[01001001]  |  [Modifier String]  |  [01001001]
			\end{equation}
			\begin{equation}
				\upsilon_i^i  |  \upsilon_1^1  |  \upsilon_i^i
			\end{equation}

\paragraph{Valid or Invalid}
		\subparagraph{Identity validity within an event space}
			Validity is an assertion that governs the boundaries (entropy) of an identity in a context(event space).  Any value of identity ($\Upsilon i$) with cardinality that is NOT the same as $\iota$ instantiates a sub-ordinate or super-ordinate identity to satisfy completeness and consistency.  it is required that $\upsilon$ is a non-null value.
		
		\begin{equation}
			i \rightarrow \aleph_0 \rightarrow (\aleph_0 + \epsilon) \Rightarrow \upsilon_i
		\end{equation}
		\begin{equation}
			\upsilon_i = i_1 >= (1-i_0)/i_0 \Rightarrow TRUE \rightarrow valid {super ordinate}
		\end{equation} 
		\begin{equation}
			\upsilon^i = i^1 <= (1-i_0)/i_0 \Rightarrow TRUE \rightarrow valid {sub ordinate}
		\end{equation}
		False cases require instantiation of a sub-ordinate or super-ordinate identity to evaluate the topological group as a valid identity.  False cases instantiate event spaces with alternate cardinalities.
		\begin{equation}
			False \Rightarrow \upsilon_i = i_1 <= (1-i_0)/i_0 \Rightarrow (\upsilon_1 + \epsilon^i) \rightarrow valid {super ordinate} 
		\end{equation}
		\begin{equation}
			False \Rightarrow \upsilon^i = i^1 >= (1-i_0)/i_0 \Rightarrow (\upsilon^1 + \epsilon_i) \rightarrow valid {sub ordinate}
		\end{equation}

		\paragraph{examples of ordinates} 
			Ordinates ascend from low entropy to high entropy.	\newline
			[010010010101] = Valid Superordinate (Greater entropy than $\dot \iota$) $\rightarrow$ $\dot \iota^1$ \newline
			[01001001] = $\dot \iota$ \newline
			[01001] = Valid Subordinate (less entropy than i) $\rightarrow$ $\dot \iota_1$ \newline
			Key Phrase: "i is not more complex than the system i exists in"  Also, "The unique components of i are not more complex or numerous than i" \newline


			[01001] = invalid superordinate (less entropy than $\dot \iota$ but noted $\dot \iota^1$) \newline
			[01001001] = $\dot \iota$ \newline
			[010010010101] = invalid subordinate (more entropy than $\dot \iota$ but noted $\dot \iota_1$) \newline \\
				Invalid ordinates can be resolved through manifold $\epsilon$ where the value of $\epsilon$ describes non-$\dot \iota$ context.
			Key Phrase: "if $\dot \iota^1$ has less complex components that govern the expression of i, then those components are part of a greater context" and "if $\dot \iota_1$ is more complex than i, there exists a unique event that gives substance to that $\dot \iota_1$" (manifold $\epsilon$ gives context to $\dot \iota_1$)


		\paragraph {Common Description} Identity is a singular immeasurable object in a dimensional plane that must use other objects to provide context to its existence. This is the negative space that has no characteristics, all instantiation comes from providing context to prove existence but does not represent existence itself. \\

	\begin{equation}
		\dot \iota = \sum_{\tau=0}^{i=PK_0} \epsilon^i_v
	\end{equation}

\subsection{Definition of Event}
	\paragraph{Datalogical Definition}A space in which a value occurs.\\\\
		\textbf{Parameters:}  Requires an upper bound - usually Pi\\
		\textbf{Extensability:}  Events occur within a given context, instantiated by an Identity Value\\
		\textbf{Entropy:} Events reduce entropy of a system by creating computational boundaries where an Identity can be expressed. \\
		\textbf{Bounds:} ($\Pi$, 0) (0, $\Pi$) Intercept ($\Pi$, $\Pi$)  \\ 
		\textbf{Coordinate:} (x,y) \\
		Events can occur in any dimension.  Boundries of an Event are defined within the context that they are presented.
			\begin{equation}
				\dot \epsilon \cup \hat \epsilon \cup \bar \epsilon \rightarrow event \Rightarrow energy \Rightarrow Transaction \rightarrow \tau
			\end{equation}
		\paragraph{CS Morphology} an event is defined as the expenditure of energy to create an object with an identity. In the Cybernetic realm, an event is the space where an identity exists.  An event space is a basic manifold that expresses an identity within a context.
			
	\subsection{Definition of Value}
			Value (v) is defined as either an object (omega) or an assertion (alpha) and/or an intersection of an object, or assertion.
			\begin{equation}
			\sigma^n \forall (\Omega^n \cap \alpha ^n) 
			\end{equation}


 Specific to the Definition of value 'n' is defined as the cardinality of value across dimensions.  Suboordinate the the notion of cardinality, we can define the following:
		\begin{equation}
			\sigma_1 = Value
		\end{equation}
			Any Non-Null pattern.
		\begin{equation}
			\sigma^1_1 = Concept
		\end{equation}
			Any pattern defined by two values (i.e. event)
		\begin{equation}
			\sigma^1_2 = Matter
		\end{equation}
			Any configuration of value that can be expressed in cybernetic space-time.
\subsection{Definition of Object}
	\paragraph{A Type of Value}
		An object is a Primitive Data type that resides within context to provide meaningful evidence of it's existence.
		1st order values of Objects are Person or Property.
			\begin{equation}
				\omega \cup \Omega \rightarrow Object \Rightarrow Person \cap Property
			\end{equation}
		2nd order Values of Objects fall into the following:
			\begin{equation}
				Person \Rightarrow Real \cap Ficticious
			\end{equation}
			
			\begin{equation}
			Property \Rightarrow Real \cap Personal \cap Intellectual \cap Public
			\end{equation}

\subsection{Definition of Assertion}
	\paragraph{A Type  of Value}
		An assertion is a primitive data type that represents the movement of an object within an event space.
		1st order values of assertions are Principles or Transaction.
			\begin{equation}
				\dot \alpha \cup \hat \alpha \cup \bar \alpha \rightarrow Assertion \Rightarrow Principle \cap Transaction
			\end{equation}		


		2nd order values of assertions fall into the following:

			\begin{equation}
				Principle \Rightarrow Primitive \cap Legal \cap Standard
			\end{equation}
			
			\begin{equation}
				Transaction \Rightarrow Claim \cap Function \cap Action
			\end{equation}



\subsection{Definition of Datum}
	\paragraph{Datalogical Mass}
		Datum exist in any dimension and has the non-reduceable quantification of datalogical mass of 1.
			\begin{equation}
				\dot \delta \rightarrow datum \Rightarrow Mass \rightarrow 1
			\end{equation}
		\subparagraph{Systemic Equivalence}
			In the physical world, datum is defined as any object in the universe with a finite and measurable identity. Any physical matter in the universe is at the intersection of Three Values (Matter). In the Cybernetic realm, an event in the object or assertion that changes the value of an identity.

\section{Basic Data Structures}
\subsection{Definition of Terms}
	\subsubsection{Private Key}	
		Private key is a non-stored unique identifier.  The Private Key is the computational equivalent to identity.
		\begin{equation}
			\hat \iota \rightarrow PK_0 \Rightarrow Private Key
		\end{equation}
	\subparagraph{Systemic Equivalence}
		When developing cybernetic identity systems, a Private Key should have the following characteristics:
\begin{enumerate}
			\item {High mathematical entropy}
			\item {Computationally consistent within it's context}
			\item {Human meaningful}
\end{enumerate}
	\subsubsection{Public Action Key}
		Public Action Key is also known as a Public Key. The Public Action Key is an object that, depending on context, can represent an assertion.
		\begin{equation}
			\phi \rightarrow PAK_0 \Rightarrow Public Action Key
		\end{equation}
	\subparagraph{Systemic Equivalence}

\begin{table}[!th]
\begin{tabular}{|l|c|r|}
\hline
Type & symbol\\
Identity & $PK_o$\\
Identity Public Action Key & $PK_1$\\
Location & $\lambda_n$\\
Validator Public Action Key & $\theta_v$\\
Observer 1 Public Key & $\phi^1$\\
Observer N Public Key & $\phi^n$\\
Observer Location & $\lambda_(_1_+_n_)$\\
Observer Context & $\gamma$\\
Action Asset Private Key & $PK_\lambda$\\
\hline
\end{tabular}
\caption{Minimal Data Requirements for an Identity with Unconstrained purpose.}
\label {Table1}
\end{table}

\begin{equation}
\frac{1}{x} = x = Diagnose
\end{equation}

\begin{equation}
x^n , x^{\frac{1}{n}} = n = Recovery
\end{equation}

\begin{equation}
\frac{x}{\phi} = \phi = Rollback
\end{equation}

\begin{equation}
\[f(\mu) = \left\{
  \begin{array}{lr}
    \int_0^x {e} \\
     \int_0^x {ln}
  \end{array}
\right]  = Retry
\end{equation}
\begin{equation}
\[f(\mu) = \left\{
  \begin{array}{lr}
    \int_x^0 min{\frac{1}{x}}, min{-\frac{1}{x}}
  \end{array}
\right]  = Mask
\end{equation}

\begin{equation}
\frac{C}{D} = \Pi_x = \Pi = Confinement
\end{equation}

\begin{equation}
\log{x}, \log\frac{1}{x} = Serialize
\end{equation}

\begin{equation}
r=1-ae^{b\theta }
\end{equation}
	
\subsubsection{Validator}
	A location that instantiates an action, Null knowledge about it's context, only verifies that an event takes place.
		\begin{equation}
		\theta \rightarrow Validator
		\end{equation}
		\subparagraph{Systemic Equivalence}
			

\subsubsection{Observer}
	a location that observes actions occurring at validator nodes. Observers cannot validate transactions, Observers are only allowed to provide context to Validators.
		\begin{equation}
		\Phi \rightarrow Observer
		\end{equation}
		\subparagraph{Systemic Equivalence}
			
\subsubsection{Location}
	A location is any identifiable point in the known universe with consideration for the warping of gravity.
		\paragraph{}
			\begin{equation}
				\frac{xyzt}{gt} \rightarrow Location \leftrightarrow node \Rightarrow \Lambda
			\end{equation}
		\subparagraph{Systemic Equivalence}
			A node is a fixed physical or datalogical point of reference.  For our purposes, any reference to "node" is to most closely describe a finite object with a clearly defined identity at the intersection of three dimensional values.
			

\subsubsection{Action Asset}
		\begin{equation}
			AAPK_0 \rightarrow Action Asset Private Key
		\end{equation}
		\subparagraph{}
			Action Asset Private key is the token used to instantiate activity of an Action (event trigger).	

\subsubsection{Context}
		\begin{equation}
		\gamma \rightarrow Context
		\end{equation}
		\subparagraph{}
			Context is a set of environmental variables that give an object purposeful and meaningful existence.
			\begin{equation}
				\gamma \rightarrow DP \cap LT \cap LE \cap LN
			\end{equation}
	
\subsection{Definition of Unconstrained Purpose}
		We define unconstrained purpose as the existence of an object at a location without instantiating an event.  The fundamental description requires:



Unconstrained purpose requires an identity private key that represents the Public Key, concurrent location and the Public Action Key from the Validator.  Additionally, it is required that the number of Observers is greater than the number of Validators, and that there is a defined location where the observers reside. For completeness, an Observer should provide context to both the Identity and Validator, and an Action Asset should be present to instantiate a transformation.
		\begin{equation}
			PK_0 \rightarrow (PAK_0 + (\Lambda)) + PAK^1_v) + (PAK_o^1 + PAK_o^2 + (\Lambda) + {\gamma} + {AAPK_1})
		\end{equation}


	
\section{Basic Rules of Recognition}
For a functional Cybernetic sytem, we look at strategies employed by organisms.

\subsection{Global Rules of Recognition}

\subsection{Object Recognition}

\subsection{Assertion Recognition}
	
		\paragraph{Transaction}
		\begin{equation}
		\epsilon \rightarrow \tau \Rightarrow Transaction
		\end{equation}
		\subparagraph{}
			Any action or set of actions reducible to a set of values.  Transactions are instantiated at a validator, broadcast to validation peers, and given context and recognition by observers.  Transactions can be considered valid or invalid. Generally, the following rule applies to a meaningful and purposeful transaction:

\section{Acknowledgements}
	Tox User: mnsdkj  
	Public Key: 1C8AF149CE5F38BF5F5022C61B85F297F8F1F55D3DCE16576607DCEBFE5C2377

\section{references}




\newpage
	
\end{document}
